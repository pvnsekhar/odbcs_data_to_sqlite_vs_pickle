{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBdqKELtqag9gw1QidtOs2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pvnsekhar/odbcs_data_to_sqlite_vs_pickle/blob/main/data_push_to_sqlite_vs_pickle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: load all files present in the folder to sqlite inmemory database\n",
        "\n",
        "import sqlite3\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def load_files_to_sqlite(folder_path):\n",
        "    \"\"\"Loads all CSV and TXT files from a folder into an in-memory SQLite database.\n",
        "\n",
        "    Args:\n",
        "        folder_path: The path to the folder containing the files.\n",
        "    \"\"\"\n",
        "    conn = sqlite3.connect(':memory:')  # Use in-memory database\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(('housing_train.csv', '.txt')):  # Process CSV and TXT files\n",
        "            filepath = os.path.join(folder_path, filename)\n",
        "            try:\n",
        "                if filename.endswith('.csv'):\n",
        "                    df = pd.read_csv(filepath)\n",
        "                else:  # Assume TXT file is space-separated\n",
        "                    df = pd.read_csv(filepath, delim_whitespace=True)\n",
        "\n",
        "                table_name = filename[:-4]  # Use filename as table name (without extension)\n",
        "                df.to_sql(table_name, conn, if_exists='append', index=False) #Replace table if exists\n",
        "\n",
        "                print(f\"Successfully loaded '{filename}' into table '{table_name}'\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading '{filename}': {e}\")\n",
        "\n",
        "    return conn\n",
        "\n",
        "# Example usage (replace with your folder path)\n",
        "folder_path = \"sample_data\"  # Example folder path\n",
        "conn = load_files_to_sqlite(folder_path)\n",
        "\n",
        "# Now you can query the database\n",
        "cursor = conn.cursor()\n",
        "# Example query (replace 'your_table_name' with the actual table name)\n",
        "cursor.execute(\"SELECT * FROM california_housing_train\")\n",
        "results = cursor.fetchall()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BCSepZsUVcl4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e282ad47-8861-4cc7-f63b-a6a3cd58cdac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded 'california_housing_train.csv' into table 'california_housing_train'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import io\n",
        "\n",
        "buffer=io.BytesIO()\n",
        "pickle.dump(results,buffer)"
      ],
      "metadata": {
        "id": "JNYMfLN3Zble"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create a table in sqlite using california_housing_train.csv file\n",
        "\n",
        "# Assuming 'conn' from the previous code is still available\n",
        "\n",
        "conn1 = sqlite3.connect(':memory:')  # Use in-memory database\n",
        "cursor = conn1.cursor()\n",
        "\n",
        "# Create a new table named 'housing_data' if it doesn't exist\n",
        "cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS housing_data (\n",
        "        longitude REAL,\n",
        "        latitude REAL,\n",
        "        housing_median_age REAL,\n",
        "        total_rooms REAL,\n",
        "        total_bedrooms REAL,\n",
        "        population REAL,\n",
        "        households REAL,\n",
        "        median_income REAL,\n",
        "        median_house_value REAL\n",
        "    )\n",
        "''')\n",
        "\n",
        "cursor.executemany(\"INSERT INTO housing_data VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\", results)\n",
        "\n",
        "\n",
        "conn1.commit() # Commit the changes to make them persistent\n"
      ],
      "metadata": {
        "id": "I_-QT4J4bwS9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: dump pickle data to a csv file\n",
        "\n",
        "import csv\n",
        "\n",
        "buffer.seek(0)  # Rewind the buffer to the beginning\n",
        "\n",
        "# Now write the pickle data to a CSV file\n",
        "with open('output.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "\n",
        "    # Write the header (optional, but recommended)\n",
        "    # Assuming results is a list of tuples/lists with the same structure as your table\n",
        "    if results:\n",
        "        header = ['longitude',\n",
        "        'latitude',\n",
        "        'housing_median_age',\n",
        "        'total_rooms',\n",
        "        'total_bedrooms',\n",
        "        'population',\n",
        "        'households',\n",
        "        'median_income',\n",
        "        'median_house_value']  # Get column names from the cursor\n",
        "        writer.writerow(header)\n",
        "\n",
        "    # Iterate through the pickled data and write each row to the CSV\n",
        "    for row in pickle.load(buffer):\n",
        "      writer.writerow(row)\n",
        "\n",
        "# ... (rest of your existing code) ..."
      ],
      "metadata": {
        "id": "zYjp8luwcvFg"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}